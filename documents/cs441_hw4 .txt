In your fourth and the final homework assignment you will solidify the knowledge of resilient overlay networks by designing and implementing a simulation of a cloud computing facility, specifically a reliable overlay network using the Chord algorithm for distribution of work in a cloud datacenter. Your goal is to gain experience with the fundamentals of distributed hash tables (DHTs) and reallocation of resources in the cloud environment. You will implement a cloud simulator in Scala using Akka actors and you will build and run your project using the SBT with the runMain command from the command line. In your cloud simulator, you will create the following entities and define interactions among them: actors that simulate users who enter and retrieve data from the cloud, actors who represent computers (i.e., nodes) in the cloud that store the data, and case classes that represent data that are sent to and retrieved from the cloud. The entry point to your simulated cloud will be defined with a RESTful service using Akka/HTTP. You will use the latest community version of IntelliJ IDE for this assignment, as usual.

WARNING: there are a few implementations of cloud simulators and Chord implementations on the Internet. I know about (almost) all of them. You are ok to learn by studying these implementations and feel free to use the ideas in your own implementation, and you must acknowledge what you use in your README. However, blindly copying large parts of some existing implementation in your code will result in receiving the grade F for the entire course with the transfer of your case of plagiarism to the Dean of Students Office, which will be followed with severe penalties. Most likely, you will be suspended or complete dismissed from the program in the worst case. Please do not plagiarize existing implementations, it is not worth it!

The input to your cloud simulator is the number of users, the number of the computers in the cloud, the minimum and the maximum number of requests per minute that each user actor can send, the duration of the simulation in minutes (more than one and less than 1000), the time marks (e.g., minute 10 during 20min simulation) when the system will capture a global state for testing (see the explanation below), the list of the items in a file (e.g., list of movies that include the title, the year, and the revenue), and the ratio of read/write requests. A read request will retrive an item from the cloud (e.g., a movie using its title/year) and a write request will store an item in the cloud (e.g., uploading a movie using its title/year - of course the GBs of data that contain the actual movie content will not be uploaded). You will use a random generator to generate the number of requests for each actor that represents users using the proposed ratio. The semantics of the data (e.g., movies, books, simply records) does not matter - feel free to chose whatever you want. Once created, actors that represent users will generate and send data to the cloud endpoint(s), which will then use the Chord algorithm to deliver this data to the actors that simulate computers to store or to retrieve the data from computers, err, actors. You will use a logging framework to log all requests sent from actors and received by the cloud and responses that are returned by the cloud actors. The log will serve as the output verification of the functionality of your cloud simulator.

Your main work is in implementing the Chord algorithm that we study in class, which is a realization of a DHT protocol that is described in the paper that is the mandatory reading material for this class: Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications. In your simulator, Chord will store key-value pairs and find the value associated with a key that is submitted by an actor that simulates a user. To accomplish this task, Chord distributes actors that simulate computers over a dynamic network of virtual nodes (you can assume one computer per node), and it implements a protocol for finding these objects once they have been placed in the overlay network. As you can imagine, there is an invisible network that connects computers that are simulated by the actors, however, actors impose their own overlay network by using Chord to send messages directly to one another. Every node in this network is simulated as an actor for looking up keys for user actors and for determining which actors will serve as key stores.

Every key inserted into the DHT must be hashed, so that Chord will determine a node designated by the hashed value of the key, which is an m-bit unsigned integer. According to Chord, the the range of hash values for the DHT contains between 0 and (2 power m-1) inclusive. You can use a 128-bit (or a higher bit content) hash values produced by message digest algorithms such as MD5 or SHA-1. An example of using MD5 in Scala is the following:
import java.security.MessageDigest
def md5(s: String) = { MessageDigest.getInstance("MD5").digest(s.getBytes) }
val hashValue = md5("CS441_hw4").

Actors that simulate nodes in the simulated cloud have the corresponding hash values that can be generated using unique names that your will assign to these nodes and they will be ordered based on those hashes. Recall from the paper and the lecture that Chord orders all nodes in a ring, in which each node's successor is the node with the next highest hash value. To complete the circle, the node with the largest hash value has the node with the smallest hash value as its successor. Of course, if an item does not exist in the cloud, a corresponding "not found" message will be returned to the user actors in response to their get requests.

To locate the node at which a particular key-value pair is stored, the successor to the hash value of the key should be located. That is, to look up a key, a request is sent around the ring, so that each node (after determining that it does not hold the value itself) determines whether its successor is the owner of the key, and forwards the request to this successor. As part of Chord, the node asks its successor to find the successor of the key interatively, repeating the search procedure until the node is found or the error message is produced. This is done using the finger table at each node. Details are discussed in the paper and in my lecture. To recapitulate briefly, the number of entries in the finger table is equal to m, where m is defined above. Entry e in the finger table, where 0 <= e < m, is the node which the owner of the table believes is the successor for the (hash value + 2 power e). When some node actor N receives a request to find the successor of the key defined by HV (hash value), it first determines whether N or N's successor is the owner of HV, and if so, then N services the request or forwards it to the successor. Otherwise, N locates a node in its finger table such that this node has the largest hash smaller than HV, and forwards the request to this node actor. You can implement variations of this algorithm and describe it in your README.

As part of testing, you must capture the global state of the system in the JSON or the XML format and dump it. The time during which the dump occurs is defined as the input to the simulator program. In your simulated world, the simulator has the power to freeze the system and walk over all actors to obtain their local states and combine them into the global state that it can save into a file whose location is defined as part of the input. After dumping the state into the file, the simulator resumes the process.

For an additional bonus (up to 5%!) you need to design the computer simulating actors to use a NoSQL storage of your choice (e.g., Neo4J or Cassandra), preferably, MemcacheDB. In addition, you need to model nodes joining, leaving, and failing. You may model increased node latencies and data replicas across the entire cloud. To receive this additional bonus, you need to implement and to describe how you will have implemented these additional features, where in the code they are located, and how to run tests to verify these functionalities.

This is an individual homework. It differs from the previous homework 3, since you are NOT allowed to form groups. If you submitted your previous homeworks, it means that you were already added as a member of UIC_CS441_2016 team in Bitbucket. Separate repositories will be created for each of your homeworks and for the course project. You will find a corresponding entry for this homework. You will fork this repository and your fork will be private, no one else besides you, the TA and your course instructor will have access to your fork. Please remember to grant a read access to your repository to your TA and your instructor. You can commit and push your code as many times as you want. Your code will not be visible and it should not be visible to other students. When you push your project, your instructor and the TA will see you code in your separate private fork. Making your fork public or inviting other students to join your fork will result in losing your grade. For grading, only the latest push timed before the deadline will be considered. If you push after the deadline, your grade for the homework will be zero. For more information about using git and bitbucket specifically, please use this link as the starting point https://confluence.atlassian.com/bitbucket/bitbucket-cloud-documentation-home-221448814.html. For those of you who still struggle with Git, I keep recommending a book by Ryan Hodson on Ry's Git Tutorial. The other book called Pro Git is written by Scott Chacon and Ben Straub and published by Apress and it is freely available https://git-scm.com/book/en/v2/. There are multiple videos on youtube that go into details of Git organization and use.

As your TA specified, please follow this naming convention while submitting your work : "Firstname_Lastname_hw4", so that we can easily recognize your submission. I repeat, please make sure that you will give both your TA and me read access to your private forked repository.

As usual, I allow you to post questions and replies, statements, comments, discussion, etc. on Piazza either using your real names or anonymously. Remember that you cannot share *your* code and your solutions, but you can ask and advise others using Piazza on where resources and sample programs can be found on the internet, how to resolve dependencies and configuration issues, and how to design the logic of the algorithm, as usual. Yet, your implementation should be your own and you cannot share it. Alternatively, you cannot copy and paste someone else's implementation and put your name on it. As I mentioned above, your submissions will be checked for plagiarism. When posting question and answers on Piazza, please select the appropriate folder, i.e., hw4 to ensure that all discussion threads can be easily located.

Submission deadline: Saturday, November 19 at 6AM CST. Your submission will include your source code, the SBT build configuration, the README.md file in the root directory that contains the description of your implementation, how to compile and run it using SBT, and what are the limitations of your implementation.

THE INSTRUCTOR AND THE TA WILL NOT ANSWER ANY REQUESTS FROM STUDENTS STARTING 7PM THE NIGHT BEFORE THE SUBMISSION DEADLINE.

Evaluation criteria:
- the maximum grade for this homework is 10% + up to 5% bonus. Points are subtracted from this maximum grade: for example, saying that 2% is lost if some requirement is not completed means that the resulting grade will be 10%-2% => 8%;
- no comments or highly insufficient comments: up to 3% lost;
- no unit and integration tests: up to 5% lost;
- code does not compile or it crashes unexpectedly without completing the core functionality: up to 5% lost;
- the documentation is missing or insufficient to understand how to compile and run your program: up to 7% lost;
- only a subset of your tests pass: up to 5% lost;
- the minimum grade for this homework cannot be less than zero.